#Results

```{r, echo = FALSE}
load('../data/best-ols.RData')
load('../data/best-ridge.RData')
load('../data/best-lasso.RData')
load('../data/best-pcr.RData')
load('../data/best-plsr.RData')
library(xtable)
options(xtable.comment = FALSE)
```

```{r, echo = FALSE, comment = NA, results = 'asis'}
reg_coef = matrix(c(ols_coefficients[-1], best_ridge, best_lasso, best_pcr, best_plsr), nrow = 11)

rownames(reg_coef) = c('Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'GenderFemale', 'StudentYes', 'MarriedYes', 'EthnicityAsian', 'EthnicityCaucasian')

colnames(reg_coef) = c('OLS', 'Ridge', 'Lasso', 'PCR', 'PLSR')

reg_coef = as.data.frame(reg_coef)
print(xtable(reg_coef, caption = 'Regression Coefficients for All Methods'))
```

The table above displays the regression coefficients of the best model for each method.  There are some things that stand out.  First, the OLS coefficients 
seem very different from the others.  This was expected, because OLS is the weakest method in this project.  Second, ridge/lasso and pcr/plsr seem to share similar regression coefficients values.  This is also expected, because each pair is similar to each other.

```{r, echo = FALSE, comment = NA, results = 'asis'}
mse = matrix(c(ridge_mse, lasso_mse, pcr_mse, plsr_mse), nrow = 1)

rownames(mse) = 'MSE'

colnames(mse) = c('Ridge', 'Lasso', 'PCR', 'PLSR')

mse = as.data.frame(mse)
print(xtable(mse, caption = 'MSEs for All Methods'))
```

The table above shows the mean squared errors for each method.  These values
were calculated by applying the best model to the test set and calculating the mean of squared difference between estimated value and actual value (Balance).  It is clear that PCR and PLSR have low MSEs compared to the other methods.

```{r, echo = FALSE, comment = NA, results = 'asis'}
library(ggplot2)

official = matrix(c(ols_coefficients, ridge_coefficients, lasso_coefficients,pcr_coefficients, plsr_coefficients), nrow = 12)

colnames(official) = c('OLS', 'Ridge', 'Lasso', 'PCR', 'PLSR')
rownames(official) = c('Intercept', 'Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'GenderFemale', 'StudentYes', 'MarriedYes', 'EthnicityAsian', 'EthnicityCaucasian')

label = c('Int', 'Income', 'Limit', 'Rating', 'Cards', 'Age', 'Edu', 'Gender',
'Student', 'Married', 'Asian', 'Caucasian')

plot(official[,1], 
     main = 'OLS official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,2], 
     main = 'Ridge official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,3], 
     main = 'Lasso official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,4], 
     main = 'PCR official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance',
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,5], 
     main = 'PLSR official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)
```

These are the 'official' regression coefficients that were calculated by applying the best model to the full data set.

