---
title: "Predictive Modeling Processes on Credit Data"
author: "Alexander Lee and Youngshin Kim"
date: "November 4, 2016"
output: pdf_document
---

#Abstract

This project functions as an introduction to ridge regression, lasso regression, principal components regression, and
partial least squares regression, particularly in R. We use R to run each of these regressions and compare the coefficients
determined by these regressions to those generated by the original least squares regression.

#Introduction

This project aims to predict data using differnet methods.
Methods used are ols, ridge, lasso, principal component regression,
and partial least sqaures regression.  We want to be able to 
predict variable 'Balance' from ten predictors.  Before we begin,
we will first make some necessary changes to our dataset using
data manipulation in R.

#Data

The data we use in this project is the credit data and it includes variable Balance, the variable we are trying to predict, and ten predictors that we use
to predict Balance.  These predictors are Income, Limit, Rating, Cards, Age, Education, GenderFemale, StudentYes, MarriedYes, EthnicityAsian, EthnicityCaucasian.  The last two predictors were originally one predictor, but
it was expanded as a result of dummifying the values.

#Methods

We use five regression methods in this project: OLS, ridge, lasso, pcr, plsr and check the method that gives us the lowest MSE. 
OLS is the most simple regression method that tries to fit a line that 
minimizes the residual sum of squares.  The rest are all regularization method. Ridge and lasso regressions are shrinkage methods that put a 
penalty to our linear model and we try to find the best model with the 
smallest lambda. Lasso is different from ridge in that lasso does variable selection.  It cuts out predictors that are not useful to predicting Balane.  PCR and PLSR regressions perform dimension reduction, and are useful when the predictors are correlated to each other.

#Analysis

For OLS, we simply fit the lm function in R.  For the rest of the methods,
we first use 10 fold cross-validation to fit method on train set and find the best model based on minimum lambda for ridge/lasso and minimum prediction error sum of squares for pcr and plsr.  Next, we apply the best model to test set and calculate MSE.  Finally, we choose the regression method that gives us the lowest MSE.

#Results

```{r, echo = FALSE}
load('../data/best-ols.RData')
load('../data/best-ridge.RData')
load('../data/best-lasso.RData')
load('../data/best-pcr.RData')
load('../data/best-plsr.RData')
library(xtable)
options(xtable.comment = FALSE)
```

```{r, echo = FALSE, comment = NA, results = 'asis'}
reg_coef = matrix(c(ols_coefficients[-1], best_ridge, best_lasso, best_pcr, best_plsr), nrow = 11)

rownames(reg_coef) = c('Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'GenderFemale', 'StudentYes', 'MarriedYes', 'EthnicityAsian', 'EthnicityCaucasian')

colnames(reg_coef) = c('OLS', 'Ridge', 'Lasso', 'PCR', 'PLSR')

reg_coef = as.data.frame(reg_coef)
print(xtable(reg_coef, caption = 'Regression Coefficients for All Methods'))
```

The table above displays the regression coefficients of the best model for each method.  There are some things that stand out.  First, the OLS coefficients 
seem very different from the others.  This was expected, because OLS is the weakest method in this project.  Second, ridge/lasso and pcr/plsr seem to share similar regression coefficients values.  This is also expected, because each pair is similar to each other.

```{r, echo = FALSE, comment = NA, results = 'asis'}
mse = matrix(c(ridge_mse, lasso_mse, pcr_mse, plsr_mse), nrow = 1)

rownames(mse) = 'MSE'

colnames(mse) = c('Ridge', 'Lasso', 'PCR', 'PLSR')

mse = as.data.frame(mse)
print(xtable(mse, caption = 'MSEs for All Methods'))
```

The table above shows the mean squared errors for each method.  These values
were calculated by applying the best model to the test set and calculating the mean of squared difference between estimated value and actual value (Balance).  It is clear that PCR and PLSR have low MSEs compared to the other methods.

```{r, echo = FALSE, comment = NA, results = 'asis'}
library(ggplot2)

ridge_coefficients = as.vector(credit_pred)
lasso_coefficients = as.vector(credit_pred_lasso)
pcr_coefficients = append(c('Intercept' = 0), pcr_coefficients)
plsr_coefficients = append(c('Intercept' = 0), plsr_coefficients)

official = matrix(c(ols_coefficients, ridge_coefficients, lasso_coefficients,pcr_coefficients, plsr_coefficients), nrow = 12)

colnames(official) = c('OLS', 'Ridge', 'Lasso', 'PCR', 'PLSR')
rownames(official) = c('Intercept', 'Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'GenderFemale', 'StudentYes', 'MarriedYes', 'EthnicityAsian', 'EthnicityCaucasian')

label = c('Int', 'Income', 'Limit', 'Rating', 'Cards', 'Age', 'Edu', 'Gender',
'Student', 'Married', 'Asian', 'Caucasian')

plot(official[,1], 
     main = 'OLS official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,2], 
     main = 'Ridge official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,3], 
     main = 'Lasso official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,4], 
     main = 'PCR official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance',
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)

plot(official[,5], 
     main = 'PLSR official coefficients', 
     xlab = 'Predictors', 
     ylab = 'Balance', 
     xaxt = 'n', col = 'red')
axis(1, at = 1:12, labels = label)
```

These are the 'official' regression coefficients that were calculated by applying the best model to the full data set.

#Conclusion

From the tables and figures above, we can conclude that PCR/PLSR give us 
the best estimate of Balance.  We can make this conclusion, because 
PCR/PLSR gave us the lowest MSE (0.05), which means the predicted values and the actual values weren't that much different from each other.  Also, from the figures above, we can assume that there were only a couple predictors that were actually important in estimating Balance.  The most noticeable predictors are Limit and Student.  It's clear in the figures that the coefficients are high for these predictors.
