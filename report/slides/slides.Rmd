---
title: "Predictive Modeling Process"
author: "Alexander Lee and Youngshin Kim"
date: "November 4, 2016"
output: slidy_presentation
---

#About This Project

We look at [Credit](http://www-bcf.usc.edu/~gareth/ISL/Credit.csv) data from the book *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani.

![](http://www-bcf.usc.edu/~gareth/ISL/ISL%20Cover%202.jpg)

#About This Project

We aim to run five different regressions on this Credit data in order to compare the predictors generated by each of these methods:

* Original least squares regression (OLS)
* Ridge regression (RR)
* Lasso regression (LR)
* Principal components regression (PCR)
* Partial least squares regression (PLSR)

#Prepping the Data

* Need to prepare the data for these regressions
  * replace factors with dummy variables
     * can't run glmnet() with factors
  * standardization and mean-centering
     * everything is on the same scale


#Prepping the Data

Before:
```{r, echo=FALSE}
raw_credit <- read.csv('../../data/raw-credit.csv')
head(raw_credit[,2:7], 10)
```

After:
```{r, echo=FALSE}
credit <- read.csv('../../data/Credit.csv')
head(round(credit[3:8], 4), 10)
```

#Prepping the Data

* break into two groups
    * training group
        * regression applied to this group for a predictor
    * test group
        * use the results of the training group to predice the results of the test group

#Original Least Squares

The classic regression method is the original least squares (OLS) regression.

```{r, echo=FALSE}
load('../../data/best-ols.RData')
ols_coefficients
```
